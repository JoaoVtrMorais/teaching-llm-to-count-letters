{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project: Teaching an LLM to Reason\n",
        "\n",
        "In this project, you will teach an LLM to use step-by-step reasoning to answer the question: \"How many X's are there in the word Y?\"\n",
        "\n",
        "Counting letters in a word is a surprisingly complex task for an LLM. Just as human beings would not be able to answer such a question for longer words without breaking down the word into its individual letters and then counting them, LLMs cannot be similarly expected to be able to respond without using smaller reasoning steps.\n",
        "\n",
        "For example, to count the number of o's in the word room, one could use the following reasoning:\n",
        "\n",
        "```\n",
        "Question: How many of the letter \"o\" are there in the word \"room\"\n",
        "Answer: 2\n",
        "Response:\n",
        "\n",
        "<reasoning>\n",
        "Letter-by-letter spelling:\n",
        "1. r - 0 o's so far\n",
        "2. o - 1 o's so far\n",
        "3. o - 2 o's so far\n",
        "4. m - 2 o's so far\n",
        "\n",
        "The letter \"o\" appears 2 times in the word \"room\".\n",
        "</reasoning>\n",
        "<answer>\n",
        "2\n",
        "</answer>\n",
        "```\n",
        "\n",
        "In this project we will use the reinforcement learning method GRPO (Group Relative Policy Optimization, of DeepSeek fame) to take a large language model that has been fine-tuned for following instructions and teach it how to break a word down into its letters and then count the requested letter.\n",
        "\n",
        "We will complete the following steps:\n",
        "\n",
        "* Set up the notebook\n",
        "* Create a letter-counting dataset\n",
        "* Create the reward functions\n",
        "* Train the model\n",
        "* View the results\n",
        "\n",
        "NOTE: This notebook will have you focus on several important aspects of training a GPRO model using LoRA:\n",
        "\n",
        "1. Configuring LoRA adapters for parameter-efficient fine tuning\n",
        "2. Selecting reward functions that help the model efficiently find its way to the correct answer (also called reward shaping)\n",
        "3. Finding hyperparameters that help the model increase the rewards earned more quickly and reliably\n",
        "4. Learning how to start with smaller experiments and to work your way up to longer experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set up the notebook\n",
        "\n",
        "We'll install dependencies needed for the project, namely `unsloth` and `vllm`, which are useful for fine-tuning LLMs with even just 15GB of VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 210 Î¼s (started: 2025-12-22 18:34:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load ipython-autotime to see how long each cell take to run\n",
        "# No changes needed in this cell\n",
        "\n",
        "!pip install -q ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mon Dec 22 18:34:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 575.57.08              Driver Version: 575.57.08      CUDA Version: 12.9     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       On  |   00000000:00:1E.0 Off |                    0 |\n",
            "| N/A   23C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "time: 324 ms (started: 2025-12-22 18:34:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Verify we have enough GPU memory to run this project (at least 15360MiB)\n",
        "# No changes needed in this cell\n",
        "\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/voc/data/venv2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "INFO 12-22 18:39:49 [__init__.py:241] Automatically detected platform cuda.\n",
            "ERROR 12-22 18:39:58 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
            "INFO 12-22 18:40:55 [vllm_utils.py:688] Unsloth: Patching vLLM v1 graph capture\n",
            "INFO 12-22 18:40:55 [vllm_utils.py:716] Unsloth: Patching vLLM v0 graph capture\n",
            "==((====))==  Unsloth 2025.9.7: Fast Qwen2 patching. Transformers: 4.55.4. vLLM: 0.10.1.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.563 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.31. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.52%\n",
            "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.56 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 384. Num Sequences = 192.\n",
            "Unsloth: vLLM's KV Cache can use up to 4.96 GB. Also swap space = 0 GB.\n",
            "WARNING 12-22 18:40:57 [compilation.py:453] full_cuda_graph is deprecated, use cudagraph_mode=FULL instead.\n",
            "Unsloth: Not an error, but `device` is not supported in vLLM. Skipping.\n",
            "INFO 12-22 18:40:58 [utils.py:326] non-default args: {'model': 'unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', 'load_format': 'bitsandbytes', 'dtype': torch.float16, 'seed': 0, 'max_model_len': 384, 'enable_prefix_caching': True, 'swap_space': 0, 'gpu_memory_utilization': 0.4952075204419056, 'max_num_batched_tokens': 2048, 'max_num_seqs': 192, 'max_logprobs': 0, 'disable_log_stats': True, 'quantization': 'bitsandbytes', 'enable_lora': True, 'enable_chunked_prefill': True, 'compilation_config': {\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":null,\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":null,\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{},\"max_capture_size\":null,\"local_cache_dir\":null}}\n",
            "INFO 12-22 18:41:35 [__init__.py:711] Resolved architecture: Qwen2ForCausalLM\n",
            "WARNING 12-22 18:41:35 [__init__.py:2819] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 12-22 18:41:35 [__init__.py:1750] Using max model len 384\n",
            "WARNING 12-22 18:41:36 [arg_utils.py:1770] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-22 18:41:38,789\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-22 18:41:39 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 12-22 18:41:39 [llm_engine.py:222] Initializing a V0 LLM engine (v0.10.1) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=384, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"inductor\",\"custom_ops\":[],\"splitting_ops\":null,\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"epilogue_fusion\":true,\"max_autotune\":false,\"shape_padding\":true,\"trace.enabled\":false,\"triton.cudagraphs\":true,\"debug\":false,\"dce\":true,\"memory_planning\":true,\"coordinate_descent_tuning\":false,\"trace.graph_diagram\":false,\"compile_threads\":4,\"group_fusion\":true,\"disable_progress\":false,\"verbose_progress\":true,\"triton.multi_kernel\":0,\"triton.use_block_ptr\":true,\"triton.enable_persistent_tma_matmul\":true,\"triton.autotune_at_compile_time\":false,\"triton.cooperative_reductions\":false,\"cuda.compile_opt_level\":\"-O2\",\"cuda.enable_cuda_lto\":true,\"combo_kernels\":false,\"benchmark_combo_kernel\":true,\"combo_kernel_foreach_dynamic_shapes\":true,\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":2,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":true,\"pass_config\":{\"enable_fusion\":false,\"enable_noop\":false},\"max_capture_size\":192,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
            "INFO 12-22 18:41:44 [cuda.py:384] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 12-22 18:41:44 [cuda.py:433] Using XFormers backend.\n",
            "INFO 12-22 18:41:45 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "INFO 12-22 18:41:45 [model_runner.py:1080] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
            "INFO 12-22 18:41:46 [bitsandbytes_loader.py:742] Loading weights with BitsAndBytes quantization. May take a while ...\n",
            "INFO 12-22 18:41:46 [weight_utils.py:296] Using model weights format ['*.safetensors']\n",
            "INFO 12-22 18:42:17 [weight_utils.py:312] Time spent downloading weights for unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit: 30.475345 seconds\n",
            "INFO 12-22 18:42:17 [weight_utils.py:349] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.14s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:02<00:00,  2.14s/it]\n",
            "\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:18<00:00, 18.91s/it]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:18<00:00, 18.91s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-22 18:42:38 [punica_selector.py:19] Using PunicaWrapperGPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-22 18:42:39 [model_runner.py:1112] Model loading took 2.2719 GiB and 52.844643 seconds\n",
            "INFO 12-22 18:42:49 [worker.py:295] Memory profiling takes 10.23 seconds\n",
            "INFO 12-22 18:42:49 [worker.py:295] the current vLLM instance can use total_gpu_memory (14.56GiB) x gpu_memory_utilization (0.50) = 7.21GiB\n",
            "INFO 12-22 18:42:49 [worker.py:295] model weights take 2.27GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 3.86GiB.\n",
            "INFO 12-22 18:42:50 [executor_base.py:114] # cuda blocks: 7029, # CPU blocks: 0\n",
            "INFO 12-22 18:42:50 [executor_base.py:119] Maximum concurrency for 384 tokens per request: 292.88x\n",
            "INFO 12-22 18:42:50 [vllm_utils.py:721] Unsloth: Running patched vLLM v0 `capture_model`.\n",
            "INFO 12-22 18:42:50 [model_runner.py:1383] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:25<00:00,  1.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-22 18:43:15 [model_runner.py:1535] Graph capturing finished in 26 secs, took 0.56 GiB\n",
            "INFO 12-22 18:43:15 [vllm_utils.py:728] Unsloth: Patched vLLM v0 graph capture finished in 26 secs.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 12-22 18:43:16 [llm_engine.py:417] init engine (profile, create kv cache, warmup model) took 37.25 seconds\n",
            "INFO 12-22 18:43:16 [llm.py:298] Supported_tasks: ['generate']\n",
            "Unsloth: Just some info: will skip parsing ['input_layernorm', 'k_norm', 'q_norm', 'post_feedforward_layernorm', 'pre_feedforward_layernorm', 'post_attention_layernorm', 'layer_norm2', 'norm2', 'norm1', 'layer_norm1', 'post_layernorm']\n",
            "Unsloth: Just some info: will skip parsing ['input_layernorm', 'k_norm', 'q_norm', 'post_feedforward_layernorm', 'cross_attn_input_layernorm', 'pre_feedforward_layernorm', 'post_attention_layernorm', 'layer_norm2', 'norm2', 'norm1', 'cross_attn_post_attention_layernorm', 'layer_norm1', 'post_layernorm']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.9.7 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 5min 25s (started: 2025-12-22 18:38:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Load the `Qwen 2.5 3B Instruct`, and set parameters for the project\n",
        "# The first time unsloth is imported, it will do its magic and patch the modules\n",
        "# it works with. This may 2-5 minutes.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "import unsloth\n",
        "\n",
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 384  # Increase if you get errors about the sequence length\n",
        "\n",
        "# Set the LoRA rank to an appropriate value\n",
        "# Read about setting LoRA rank:\n",
        "# https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "lora_rank = 16  # Explain your choice\n",
        "\n",
        "# Load the Instruct model in 4-bit mode\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    load_in_4bit=True,  # We'll use quantization!\n",
        "    fast_inference=True,  # This uses vllm for faster inference\n",
        "    max_lora_rank=lora_rank,\n",
        "    gpu_memory_utilization=0.5,  # You can reduce this if you get an memory error\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=lora_rank,\n",
        "    target_modules=[\n",
        "        # Read about choosing adapters for LoRA:\n",
        "        # https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "        # Choose the target modules/adapters for your LoRA model\n",
        "        \"q_proj\", # For optimal performance, LoRA should be applied to all major linear layers. \n",
        "        \"k_proj\", # Research has shown that targeting all major layers is crucial for matching the performance of full fine-tuning.\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha=lora_rank,\n",
        "    use_gradient_checkpointing=\"unsloth\",  # Unsloth enables longer contexts\n",
        "    # See: https://github.com/unslothai/unsloth\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Try Prompt Engineering to Count Letters\n",
        "\n",
        "Let's work on the system prompt a little to see if we can get the model to count the number of the letter `g` in `engage`.\n",
        "\n",
        "\n",
        "Here you must:\n",
        "* Write clear instructions\n",
        "* Break the problem down into steps (Chain-of-Thought prompting)\n",
        "* Provide at least one example for the model to follow (Few-shot prompting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1088.02it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 54.01 toks/s, output: 27.94 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "There is 1 letter \"g\" in the word \"engage\".\n",
            "time: 549 ms (started: 2025-12-22 18:55:05 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# First, let's see what happens when we have a blank system prompt\n",
        "# No changes needed in this cell\n",
        "SYSTEM_PROMPT = \"\"\"\"\"\"\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Without any prompting the model will generate an output such as this:\n",
        "\n",
        "```\n",
        "=== GENERATED OUTPUT ===\n",
        "There is one letter \"g\" in the word \"engage\".\n",
        "```\n",
        "\n",
        "Now let's work on the system prompt to help the model break this problem down into steps, which might help it get the right answer (2 `g`'s in `engage`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 816.01it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 224.30 toks/s, output: 32.60 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== TEXT FOR COMPLETION ===\n",
            "<|im_start|>system\n",
            "\n",
            "You are a helpful assistant.\n",
            "\n",
            "Your task is to count how many times a specific letter appears in a given word.\n",
            "\n",
            "Follow these steps strictly:\n",
            "1. Read the word carefully.\n",
            "2. Spell the word by separating each letter with a hyphen and using uppercase letters.\n",
            "3. Count how many times the specified letter appears in the word.\n",
            "4. Output the result in the same format as the example.\n",
            "\n",
            "Example:\n",
            "\n",
            "Question:\n",
            "How many times does the letter \"a\" appear in the word \"appliance\"?\n",
            "\n",
            "Answer:\n",
            "Appliance -> A-P-P-L-I-A-N-C-E\n",
            "\n",
            "There is 2 letters \"a\" in the word \"appliance\"\n",
            "\n",
            "Now answer the next question following the same steps and format.\n",
            "<|im_end|>\n",
            "<|im_start|>user\n",
            "How many of the letter \"g\" are there in the word \"engage\"<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "=== GENERATED OUTPUT ===\n",
            "Engage -> E-N-G-A-G-E\n",
            "\n",
            "There is 1 letter \"g\" in the word \"engage\"\n",
            "time: 779 ms (started: 2025-12-22 18:55:33 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a new system prompt that will help the model break this problem\n",
        "# down into steps, for example, using \"letter-by-letter\" spelling.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Use a CoT prompt with at least one example\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "You are a helpful assistant.\n",
        "\n",
        "Your task is to count how many times a specific letter appears in a given word.\n",
        "\n",
        "Follow these steps strictly:\n",
        "1. Read the word carefully.\n",
        "2. Spell the word by separating each letter with a hyphen and using uppercase letters.\n",
        "3. Count how many times the specified letter appears in the word.\n",
        "4. Output the result in the same format as the example.\n",
        "\n",
        "Example:\n",
        "\n",
        "Question:\n",
        "How many times does the letter \"a\" appear in the word \"appliance\"?\n",
        "\n",
        "Answer:\n",
        "Appliance -> A-P-P-L-I-A-N-C-E\n",
        "\n",
        "There is 2 letters \"a\" in the word \"appliance\"\n",
        "\n",
        "Now answer the next question following the same steps and format.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "USER_PROMPT = 'How many of the letter \"g\" are there in the word \"engage\"'\n",
        "\n",
        "# Convert the chat messages to a single string so the model can complete it\n",
        "text_for_completion = tokenizer.apply_chat_template(\n",
        "    conversation=[\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": USER_PROMPT,\n",
        "        },\n",
        "    ],\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "# Set the LLM sampling parameters\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=2048,\n",
        ")\n",
        "\n",
        "# Generate the text completion\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text_for_completion],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "# Print the text input for the model and the model's output\n",
        "print(\"=== TEXT FOR COMPLETION ===\")\n",
        "print(text_for_completion)\n",
        "print(\"=== GENERATED OUTPUT ===\")\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Did your new prompt get the right answer? Did the model follow all of your instructions?\n",
        "\n",
        "Maybe yes, maybe no. Either way, we'll want the model to reliably complete this challenge. So let's use GRPO to help it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a letter-counting dataset\n",
        "\n",
        "To train a model, we'll first need to create a dataset. We'll use the HuggingFace `datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['idea',\n",
              " 'glow',\n",
              " 'rust',\n",
              " 'maze',\n",
              " 'echo',\n",
              " 'wisp',\n",
              " 'veto',\n",
              " 'lush',\n",
              " 'gaze',\n",
              " 'knit']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 5.07 ms (started: 2025-12-22 18:56:06 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a list of words of different lengths\n",
        "# No changes are needed in this cell.\n",
        "\n",
        "ALL_WORDS = [\n",
        "    \"idea\",\n",
        "    \"glow\",\n",
        "    \"rust\",\n",
        "    \"maze\",\n",
        "    \"echo\",\n",
        "    \"wisp\",\n",
        "    \"veto\",\n",
        "    \"lush\",\n",
        "    \"gaze\",\n",
        "    \"knit\",\n",
        "    \"fume\",\n",
        "    \"plow\",\n",
        "    \"void\",\n",
        "    \"oath\",\n",
        "    \"grim\",\n",
        "    \"crisp\",\n",
        "    \"lunar\",\n",
        "    \"fable\",\n",
        "    \"quest\",\n",
        "    \"verge\",\n",
        "    \"brawn\",\n",
        "    \"elude\",\n",
        "    \"aisle\",\n",
        "    \"ember\",\n",
        "    \"crave\",\n",
        "    \"ivory\",\n",
        "    \"mirth\",\n",
        "    \"knack\",\n",
        "    \"wryly\",\n",
        "    \"onset\",\n",
        "    \"mosaic\",\n",
        "    \"velvet\",\n",
        "    \"sphinx\",\n",
        "    \"radius\",\n",
        "    \"summit\",\n",
        "    \"banner\",\n",
        "    \"cipher\",\n",
        "    \"glisten\",\n",
        "    \"mantle\",\n",
        "    \"scarab\",\n",
        "    \"expose\",\n",
        "    \"fathom\",\n",
        "    \"tavern\",\n",
        "    \"fusion\",\n",
        "    \"relish\",\n",
        "    \"lantern\",\n",
        "    \"enchant\",\n",
        "    \"torrent\",\n",
        "    \"capture\",\n",
        "    \"orchard\",\n",
        "    \"eclipse\",\n",
        "    \"frescos\",\n",
        "    \"triumph\",\n",
        "    \"absolve\",\n",
        "    \"gossipy\",\n",
        "    \"prelude\",\n",
        "    \"whistle\",\n",
        "    \"resolve\",\n",
        "    \"zealous\",\n",
        "    \"mirage\",\n",
        "    \"aperture\",\n",
        "    \"sapphire\",\n",
        "]\n",
        "\n",
        "print(len(ALL_WORDS))\n",
        "\n",
        "ALL_WORDS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 401 examples [00:00, 9571.40 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea', 'letters': 'a', 'counts': 1}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 773 ms (started: 2025-12-22 18:56:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create the dataset as a Hugging Face Dataset using Dataset.from_generator\n",
        "# No changes needed in this cell\n",
        "\n",
        "from datasets import Dataset\n",
        "import random\n",
        "\n",
        "\n",
        "# Go through the letters from the words (as well as letters not in the words),\n",
        "# and create a labelled dataset with all the different combinations.\n",
        "# For example for the word gaze:\n",
        "# 1. How many i's are in idea? <-- count should be 1\n",
        "# 2. How many d's are in idea? <-- count should be 1\n",
        "# 3. How many e's are in idea? <-- count should be 1\n",
        "# 4. How many a's are in idea? <-- count should be 1\n",
        "# 5. How many b's are in idea? <-- a letter not in word (count should be zero)\n",
        "def generate_records():\n",
        "    for word in ALL_WORDS:\n",
        "        for letter in sorted(set(word)):\n",
        "            yield {\"words\": word, \"letters\": letter, \"counts\": word.count(letter)}\n",
        "\n",
        "        # pick random letters not in the word\n",
        "        num_letters_not_in_word_left = int(len(word) // 7 + 1)\n",
        "\n",
        "        random.seed(hash(word))\n",
        "\n",
        "        all_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
        "\n",
        "        random.shuffle(all_letters)\n",
        "        for letter in all_letters:\n",
        "            if letter not in word:\n",
        "                yield {\"words\": word, \"letters\": letter, \"counts\": 0}\n",
        "                num_letters_not_in_word_left -= 1\n",
        "            if num_letters_not_in_word_left == 0:\n",
        "                break\n",
        "\n",
        "\n",
        "ds = Dataset.from_generator(generate_records)\n",
        "\n",
        "# Show the first item\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 401/401 [00:00<00:00, 5033.55 examples/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'words': 'idea',\n",
              " 'letters': 'a',\n",
              " 'counts': 1,\n",
              " 'prompt': [{'content': \"\\nRespond in the following format:\\n<reasoning>\\nCounting the number of [letter_to_count]'s in the word [word]\\n1. [first letter] - [count of requested letter so far] so far\\n2. [second letter] - [count of requested letter so far] so far\\n...\\n</reasoning>\\n<answer>\\n[number]\\n</answer>\\n\",\n",
              "   'role': 'system'},\n",
              "  {'content': 'How many of the letter \"a\" are there in the word \"idea\"',\n",
              "   'role': 'user'}]}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 101 ms (started: 2025-12-22 18:56:40 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Add the entire prompt (system + user) and the answer to the dataset\n",
        "# We'll use a prompt that spells out the word letter-by-letter\n",
        "# No changes needed in this cell\n",
        "\n",
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Simple CoT prompt (zero-shot)\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "Counting the number of [letter_to_count]'s in the word [word]\n",
        "1. [first letter] - [count of requested letter so far] so far\n",
        "2. [second letter] - [count of requested letter so far] so far\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "[number]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "ds = ds.map(\n",
        "    lambda x: {  # type: ignore\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": 'How many of the letter \"{}\" are there in the word \"{}\"'.format(\n",
        "                    x[\"letters\"], x[\"words\"]\n",
        "                ),\n",
        "            },\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 917.19it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 62.55 toks/s, output: 38.72 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "time: 1.69 s (started: 2025-12-22 18:56:53 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see how well the model runs out-of-the-box\n",
        "# No changes needed in this cell\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    ds[0][\"prompt\"], tokenize=False, add_generation_prompt=True\n",
        ")\n",
        "\n",
        "from vllm import SamplingParams\n",
        "\n",
        "sampling_params = SamplingParams(\n",
        "    temperature=0.8,\n",
        "    top_p=0.95,\n",
        "    max_tokens=1024,\n",
        ")\n",
        "output = (\n",
        "    model.fast_generate(\n",
        "        [text],\n",
        "        sampling_params=sampling_params,\n",
        "        lora_request=None,\n",
        "    )[0]\n",
        "    .outputs[0]\n",
        "    .text\n",
        ")\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Reward Functions\n",
        "\n",
        "One goal of creating reward functions is to guide the model toward behaviors that help it reach its goal (counting the occurrences of a letter within a word) more easily. Since there is more than one way to carry out any step-by-step task (e.g. whether or not you use bullet points to separate your steps), there's a bit of judgement involved in choosing what behaviors to reward, i.e. how do we provide partial credit or \"shape\" our rewards?\n",
        "\n",
        "In this case we will encourage the model to (whether or not this structure is best):\n",
        "* use numbers for bullet points when spelling out the word\n",
        "* to spell the word correctly\n",
        "* to count the requested letter correctly\n",
        "* to use the requested reasoning format\n",
        "* to get the final answer correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Numbering reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1.0, 0.5]\n",
            "time: 3.44 ms (started: 2025-12-22 19:01:57 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's work on a function that the numbering in the bullet points is correct\n",
        "# When using GRPO, we lean on reward functions that are relatively easy to\n",
        "# compute, thus removing the need to have a second large model just for\n",
        "# evaluation.\n",
        "# In this case, we'll use regular expressions quite a bit.\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_letter_numbering(response):\n",
        "    \"\"\"Extract the numbers at the beginning of the line\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [1, 2, 3, 4, 5]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    # We use a regular expression to find lines of the form:\n",
        "    # '\\n[number]. [letter]'\n",
        "    pattern = r\"\\n(\\d+). [a-z]\"\n",
        "\n",
        "    # Use `re` to find all matches of the pattern in the response\n",
        "    matches = re.findall(pattern, response)\n",
        "    if matches:\n",
        "        return [int(m) for m in matches]\n",
        "    return []\n",
        "\n",
        "\n",
        "assert extract_letter_numbering(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [1, 2, 3, 4, 5]\n",
        "\n",
        "\n",
        "def numbering_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"Provides a reward for getting the numbering at the beginning of the line correct\n",
        "\n",
        "    1. g - 1 so far <-- Good in-order numbering\n",
        "    2. o - 1 so far <-- Good in-order numbering\n",
        "    3. a - 2 so far <-- Good in-order numbering\n",
        "    3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "    1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "\n",
        "    \"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "    for response, word in zip(responses, words):\n",
        "        reward = 0\n",
        "\n",
        "        for ix, spell_number in enumerate(extract_letter_numbering(response)):\n",
        "            line_number = ix + 1\n",
        "\n",
        "            # Get points for in-order numbering\n",
        "            if spell_number == line_number:\n",
        "                # TODO: Provide a reward for in-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward += 1\n",
        "            # Otherwise lose points\n",
        "            else:\n",
        "                # TODO: Provide a reward for out-of-order numbering\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 1\n",
        "\n",
        "            # Lose extra points for continuing beyond the length of the word\n",
        "            if line_number > len(word):  # We use the index of the line\n",
        "                # TODO: Provide a reward for continuing beyond the length of the word\n",
        "                # (positive for good behavior, negative for bad)\n",
        "                reward -= 2\n",
        "\n",
        "        res.append(reward / len(word))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = numbering_reward_func(\n",
        "    completions=[\n",
        "        [\n",
        "            {  # Worse response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "1. l - 2 so far <-- Bad numbering, extra letter and out-of-order\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "        [\n",
        "            {  # Better response\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far <-- Good in-order numbering\n",
        "2. o - 1 so far <-- Good in-order numbering\n",
        "3. a - 2 so far <-- Good in-order numbering\n",
        "3. l - 2 so far <-- Bad numbering, out-of-order, 3 should be 4\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            },\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Spelling reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-312.0, -280.0]\n",
            "time: 3.52 ms (started: 2025-12-22 19:07:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward correct spelling of the word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_spelling(response):\n",
        "    \"\"\"Extract the spelling from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    3. l - 2 so far\n",
        "    5. l - 2 so far\n",
        "    Returns \"goall\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n\\d+. ([a-z])\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "    if matches:\n",
        "        return \"\".join([m for m in matches])\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "extract_spelling(\n",
        "    \"\"\"Here is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "3. l - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == \"goall\"\n",
        "\n",
        "\n",
        "def spelling_reward_func(completions, words, **kwargs) -> list[float]:\n",
        "    \"\"\"A spelling reward function.\"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for word, response in zip(words, responses):\n",
        "        reward = 0.0\n",
        "\n",
        "        # Provide a reward for exactly correct spelling\n",
        "        reward += 1.0 if response == word else 0.0\n",
        "\n",
        "        # Provide a reward for each letter of difference in length\n",
        "        reward -= abs(len(response) - len(word))\n",
        "\n",
        "        # Provide a reward for each letter that is not in the target word\n",
        "        reward -=  sum(\n",
        "            max(0, response.count(c) - word.count(c))\n",
        "            for c in set(response)\n",
        "        )\n",
        "\n",
        "        # Provide a reward for each letter that is in the target word but not in the response\n",
        "        reward -= sum(\n",
        "            max(0, word.count(c) - response.count(c))\n",
        "            for c in set(word)\n",
        "        )\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = spelling_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "5. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better Response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\n",
        "Here is a letter by letter spelling:\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. l - 2 so far\n",
        "</reasoning>\n",
        "<answer>2</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    words=[\"goal\", \"goal\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Counting reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.6, 1.0]\n",
            "time: 2.37 ms (started: 2025-12-22 19:10:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Let's reward the model for properly counting the occurrences of a letter in a word\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "# No changes needed in this cell, but feel free to experiment with variations on the prompt\n",
        "\n",
        "\n",
        "def get_resp_letters_and_counts(response):\n",
        "    \"\"\"Extract the letters and counts from the response\n",
        "\n",
        "    Example:\n",
        "    1. g - 1 so far\n",
        "    2. o - 1 so far\n",
        "    3. a - 2 so far\n",
        "    4. a - 2 so far\n",
        "    5. l - 2 so far\n",
        "    returns [('g', 1), ('o', 1), ('a', 2), ('a', 2), ('l', 2)]\n",
        "    \"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"\\n(\\d+)\\. ([a-z])\\D*(\\d+)\"\n",
        "\n",
        "    # Find strings matching e.g. \"2. a - 2 so far\"\n",
        "    matches = re.findall(pattern, response, flags=re.IGNORECASE)\n",
        "\n",
        "    if not matches:\n",
        "        return []\n",
        "\n",
        "    return [\n",
        "        (matched_letter, matched_count_so_far)\n",
        "        for _, matched_letter, matched_count_so_far in matches\n",
        "    ]\n",
        "\n",
        "\n",
        "assert get_resp_letters_and_counts(\n",
        "    \"\"\"\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 2 so far\n",
        "4. a - 2 so far\n",
        "5. l - 2 so far\n",
        "\"\"\"\n",
        ") == [(\"g\", \"1\"), (\"o\", \"1\"), (\"a\", \"2\"), (\"a\", \"2\"), (\"l\", \"2\")]\n",
        "\n",
        "\n",
        "def counting_reward_func(completions, letters, **kwargs) -> list[float]:\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    res = []\n",
        "\n",
        "    # Iterate over each of the letter-response pairs\n",
        "    for letter, response in zip(letters, responses):\n",
        "        reward = 0\n",
        "\n",
        "        letters_and_counts = get_resp_letters_and_counts(response)\n",
        "\n",
        "        # If there are no matches, provide a negative reward\n",
        "        if not letters_and_counts:\n",
        "            res.append(-1)\n",
        "            continue\n",
        "\n",
        "        # Start counting the matching letters\n",
        "        actual_count = 0\n",
        "        for resp_letter, resp_count in letters_and_counts:\n",
        "            # If there's a match, count the letter\n",
        "            if letter == resp_letter:\n",
        "                actual_count += 1\n",
        "\n",
        "            # If the count is accurate, add a reward, else subtract a reward\n",
        "            if actual_count == int(resp_count):\n",
        "                reward += 1\n",
        "            else:\n",
        "                reward -= 1\n",
        "\n",
        "        # Return the reward normalized by the length of the matches\n",
        "        res.append(reward / len(letters_and_counts))\n",
        "    return res\n",
        "\n",
        "\n",
        "res = counting_reward_func(\n",
        "    completions=[\n",
        "        [  # Worse response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 0 so far\n",
        "2. o - 0 so far\n",
        "3. a - 1 so far\n",
        "4. a - 2 so far\n",
        "5. l - 0 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "        [  # Better response\n",
        "            {\n",
        "                \"content\": \"\"\"<reasoning>\\nHere is a letter by letter spelling:\n",
        "\n",
        "1. g - 1 so far\n",
        "2. o - 1 so far\n",
        "3. a - 1 so far\n",
        "4. a - 1 so far\n",
        "5. l - 1 so far\n",
        "\n",
        "\\n</reasoning>\\n<answer>\\nThis is my answer.\\n</answer>\"\"\"\n",
        "            }\n",
        "        ],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting reward functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.0, 1.0]\n",
            "time: 2.07 ms (started: 2025-12-22 19:13:51 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the response in a specific format\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    \"\"\"Extracts the string between <answer> and </answer> tags.\"\"\"\n",
        "    import re\n",
        "\n",
        "    pattern = r\"<answer>(.*?)</answer>\"\n",
        "    match = re.search(pattern, text, re.DOTALL)\n",
        "    if match:\n",
        "        return match.group(1).strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "assert (\n",
        "    extract_xml_answer(\"\"\"\n",
        "<reasoning>\n",
        "This is my reasoning.\n",
        "</reasoning>\n",
        "<answer>SUPERCALIFRAGILISTICEXPIALIDOCIOUS</answer>\n",
        "\"\"\")\n",
        "    == \"SUPERCALIFRAGILISTICEXPIALIDOCIOUS\"\n",
        ")\n",
        "\n",
        "\n",
        "def format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"\\s*<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "\n",
        "    res = []\n",
        "\n",
        "    for completion in completions:\n",
        "        reward = 0.0\n",
        "\n",
        "        # Extract the response content\n",
        "        response = completion[0][\"content\"]\n",
        "\n",
        "        # Check if the response matches the pattern\n",
        "        match = re.match(pattern, response, flags=re.MULTILINE | re.DOTALL)\n",
        "\n",
        "        # If it matches, return 0.5, otherwise return 0.0\n",
        "        if match:\n",
        "            reward += 0.5\n",
        "        else:\n",
        "            reward += 0.0\n",
        "\n",
        "        # Extract the answer from the response\n",
        "        extracted_answer = extract_xml_answer(response)\n",
        "        # If the answer is an integer, add 0.5 to the reward\n",
        "        if extracted_answer.isdigit():\n",
        "            reward += 0.5\n",
        "\n",
        "        res.append(reward)\n",
        "    return res\n",
        "\n",
        "\n",
        "res = format_reward_func(\n",
        "    completions=[\n",
        "        [{\"content\": \"This is my answer\"}],\n",
        "        [\n",
        "            {\n",
        "                \"content\": \"<reasoning>\\nThis is my reasoning.\\n</reasoning>\\n<answer>\\n3\\n</answer>\"\n",
        "            }\n",
        "        ],\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task correctness reward function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many...\n",
            "Answer: 0\n",
            "Response: <reasoning>.../reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "[0.0, 1.0]\n",
            "time: 1.62 ms (started: 2025-12-22 19:16:23 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Reward the model for providing the correct answer\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "\n",
        "def correct_answer_reward_func(prompts, completions, counts, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward the final answer if it is correct.\"\"\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "\n",
        "    # Print a nice summary of the first prompt, answer, and response to see while training\n",
        "    print(f\"\"\"\n",
        "{\"-\" * 20}\n",
        "Question: {prompts[0][-1][\"content\"]}\n",
        "Answer: {counts[0]}\n",
        "Response: {responses[0]}\n",
        "Extracted: {extracted_responses[0]}\n",
        "Correct: {str(extracted_responses[0]) == str(counts[0])}!\n",
        "    \"\"\")\n",
        "\n",
        "    res = [\n",
        "        # Provide reward for exactly correct answer  \n",
        "        1.0 if str(r) == str(a) else 0.0\n",
        "        for r, a in zip(extracted_responses, counts)\n",
        "    ]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "res = correct_answer_reward_func(\n",
        "    prompts=[\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "        [{\"content\": \"\"\"How many...\"\"\"}],\n",
        "    ],\n",
        "    completions=[\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "        [{\"content\": \"\"\"<reasoning>.../reasoning>\\n<answer>\\n3\\n</answer>\"\"\"}],\n",
        "    ],\n",
        "    letters=[\"g\", \"g\"],\n",
        "    counts=[0, 3],\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "assert res[1] > res[0], \"The better response should have a higher reward\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### List the reward functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 395 Î¼s (started: 2025-12-22 19:16:33 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# List out the reward functions we will use\n",
        "# No changes needed in this cell\n",
        "\n",
        "REWARD_FUNCS = [\n",
        "    numbering_reward_func,\n",
        "    spelling_reward_func,\n",
        "    counting_reward_func,\n",
        "    format_reward_func,\n",
        "    correct_answer_reward_func,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\n",
        "\n",
        "Now set up GRPO Trainer and configurations!\n",
        "\n",
        "As you run the trainer, the goal is to see the various `reward` columns increase.\n",
        "\n",
        "After 50 steps or more, you may notice some of the reward standard deviations begin to decrease, meaning that the different predictions are starting to converge on solutions that give similar rewards. If your model has learned the task, then you'll see the `correct_answer_reward_function` increase to its highest value (check the function to see what that is).\n",
        "\n",
        "Here is an example, which successfully converged on a higher reward. Note, the values you see here will probably be different from yours, especially if your reward amounts are different.\n",
        "\n",
        "| Step | Training Loss | reward   | reward_std | ... | kl      | rewards / correct_answer_reward_function / mean | rewards / correct_answer_reward_function / std |\n",
        "|------|---------------|----------|------------|-----|---------|------------------------------------------|-----------------------------------------|\n",
        "| 1    | 0.000000      | 7.961805 | 2.368493   | ... | 0.020369| 0.875000                                 | 1.024695                                |\n",
        "| 2    | 0.000000      | 7.937500 | 1.352467   | ... | 0.016483| 0.875000                                 | 1.024695                                |\n",
        "| 3    | 0.000000      | 1.894792 | 6.462189   | ... | 0.013677| 0.375000                                 | 0.806226                                |\n",
        "| ...  | ...           | ...      | ...        | ... | ...     | ...                                      | ...                                     |\n",
        "| 398  | 0.000100      | 13.000000| 0.000000   | ... | 0.088529| 2.000000                                 | 0.000000                                |\n",
        "| 399  | 0.000100      | 13.000000| 0.000000   | ... | 0.088617| 2.000000                                 | 0.000000                                |\n",
        "| 400  | 0.000100      | 13.000000| 0.000000   | ... | 0.096202| 2.000000                                 | 0.000000                                |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 983 Î¼s (started: 2025-12-22 19:22:05 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Fill in the GRPO Parameters we'll use throughout this project\n",
        "# TODO: Fill in the missing parts marked with **********\n",
        "\n",
        "# Read about the GRPO params here https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "COMMON_GRPO_TRAINING_PARAMS = dict(\n",
        "    # Set appropriate values for `learning_rate` and `beta`\n",
        "    # See: https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/lora-hyperparameters-guide\n",
        "    # See: https://huggingface.co/docs/trl/main/en/grpo_trainer\n",
        "    learning_rate=5e-6,\n",
        "    beta=0.05,\n",
        "    # Set the batch size appropriately for your hardware. For GRPO there are a number of parameters to set.\n",
        "    # If you are not sure about your GPU, assume you have a T4. See the memory specs here:\n",
        "    # https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/T4%20Product%20Brief.pdf\n",
        "    per_device_train_batch_size=16,  # per_device_train_batch_size / num_generations determines the number of simultaneous prompts to consider.\n",
        "    # Note: Set per_device_train_batch_size to at most 16 on the Vocareum T4 for best stability\n",
        "    num_generations=4,  # Determines the number of completions/generations to compute for each single prompt\n",
        "    gradient_accumulation_steps=2,  # This parameter allow us to consider multiple steps in a single optimization step\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.1,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    optim=\"adamw_8bit\",\n",
        "    logging_steps=1,\n",
        "    max_prompt_length=256,\n",
        "    max_completion_length=200,\n",
        "    num_train_epochs=1,  # Set to 1 for a full training run\n",
        "    save_steps=250,\n",
        "    max_grad_norm=0.1,\n",
        "    report_to=\"none\",  # Setting this value lets us use Weights and Biases\n",
        "    output_dir=\"outputs\",\n",
        "    use_vllm=True,  # vll speeds up inference! See https://github.com/vllm-project/vllm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Quick train\n",
        "\n",
        "Let's train the model for just 5 steps (`max_steps=5`). As it runs we can double check we've set up our prompts correctly before running for a longer amount of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts:   0%|          | 0/1 [34:05<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\n",
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 1 | Total steps = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 2 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 29,933,568 of 3,115,872,256 (0.96% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of \"g\" in the word \"glisten\"\n",
            "1. g - 1 so far\n",
            "2. i - 0 so far (no other \"g\"s found after the first \"g\")\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 01:32, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-360.076965</td>\n",
              "      <td>73.155884</td>\n",
              "      <td>79.250000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.250000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.741741</td>\n",
              "      <td>0.293594</td>\n",
              "      <td>-362.500000</td>\n",
              "      <td>113.721786</td>\n",
              "      <td>-0.006200</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-390.331116</td>\n",
              "      <td>63.225990</td>\n",
              "      <td>89.312500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>89.312500</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.863095</td>\n",
              "      <td>0.231000</td>\n",
              "      <td>-392.687500</td>\n",
              "      <td>127.938095</td>\n",
              "      <td>0.149504</td>\n",
              "      <td>0.747900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-341.919556</td>\n",
              "      <td>42.640945</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>79.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.800893</td>\n",
              "      <td>0.238539</td>\n",
              "      <td>-344.750000</td>\n",
              "      <td>67.109444</td>\n",
              "      <td>0.404539</td>\n",
              "      <td>0.686618</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-359.481598</td>\n",
              "      <td>54.532089</td>\n",
              "      <td>84.406250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>84.406250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>123.000000</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.722619</td>\n",
              "      <td>0.177643</td>\n",
              "      <td>-361.750000</td>\n",
              "      <td>80.514076</td>\n",
              "      <td>0.139534</td>\n",
              "      <td>0.688091</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-384.329468</td>\n",
              "      <td>87.092484</td>\n",
              "      <td>86.031250</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>86.031250</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.821801</td>\n",
              "      <td>0.198871</td>\n",
              "      <td>-386.750000</td>\n",
              "      <td>126.885010</td>\n",
              "      <td>0.254985</td>\n",
              "      <td>0.679949</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. a - 1 so far\n",
            "5. b - 1 so far\n",
            "6. o - 1 so far\n",
            "7. v - 1 so far\n",
            "8. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. v - 1 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word \"absove\"\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. o - 0 so far\n",
            "5. v - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. ch - 0 so far\n",
            "3. ec - 1 so far\n",
            "4. cho - 1 so far\n",
            "5. echo - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "time: 2min 40s (started: 2025-12-22 19:22:09 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Train for just a few steps for a few minutes\n",
        "# This will allow us to observe the results and make any changes to our reward functions\n",
        "# before starting a longer run. Note, you won't see much change in the average.\n",
        "# reward values\n",
        "# No changes are needed here\n",
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "\n",
        "# Short train to check on reward functions\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # We'll just run for a modest 5 steps to make sure everything works and to\n",
        "    # estimate the amount of time it will take to run the full training.\n",
        "    max_steps=5,\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 9.37 s (started: 2025-12-22 19:25:01 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Slower train (1+ hour)\n",
        "\n",
        "If everything looks good, let's go for a longer training session!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 401 | Num Epochs = 2 | Total steps = 100\n",
            "O^O/ \\_/ \\    Batch size per device = 16 | Gradient accumulation steps = 2\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (16 x 2 x 1) = 32\n",
            " \"-____-\"     Trainable parameters = 29,933,568 of 3,115,872,256 (0.96% trained)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"g\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of g's in the word glisten\n",
            "1. g - 1 so far\n",
            "2. i - 1 so far\n",
            "3. s - 1 so far\n",
            "4. e - 1 so far\n",
            "5. n - 1 so far\n",
            "6. t - 1 so far\n",
            "7. l - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [100/100 27:19, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completions / mean_length</th>\n",
              "      <th>completions / min_length</th>\n",
              "      <th>completions / max_length</th>\n",
              "      <th>completions / clipped_ratio</th>\n",
              "      <th>completions / mean_terminated_length</th>\n",
              "      <th>completions / min_terminated_length</th>\n",
              "      <th>completions / max_terminated_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / numbering_reward_func / mean</th>\n",
              "      <th>rewards / numbering_reward_func / std</th>\n",
              "      <th>rewards / spelling_reward_func / mean</th>\n",
              "      <th>rewards / spelling_reward_func / std</th>\n",
              "      <th>rewards / counting_reward_func / mean</th>\n",
              "      <th>rewards / counting_reward_func / std</th>\n",
              "      <th>rewards / format_reward_func / mean</th>\n",
              "      <th>rewards / format_reward_func / std</th>\n",
              "      <th>rewards / correct_answer_reward_func / mean</th>\n",
              "      <th>rewards / correct_answer_reward_func / std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-353.816345</td>\n",
              "      <td>71.465134</td>\n",
              "      <td>78.781250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.781250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.752344</td>\n",
              "      <td>0.293021</td>\n",
              "      <td>-356.187500</td>\n",
              "      <td>112.273125</td>\n",
              "      <td>-0.006176</td>\n",
              "      <td>0.623955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-377.563171</td>\n",
              "      <td>69.539543</td>\n",
              "      <td>83.062500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.062500</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>0.000130</td>\n",
              "      <td>0.863839</td>\n",
              "      <td>0.242300</td>\n",
              "      <td>-380.000000</td>\n",
              "      <td>159.728806</td>\n",
              "      <td>0.135516</td>\n",
              "      <td>0.744415</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.504016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-358.896667</td>\n",
              "      <td>42.016277</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.250000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000202</td>\n",
              "      <td>0.886533</td>\n",
              "      <td>0.123933</td>\n",
              "      <td>-361.937500</td>\n",
              "      <td>61.689095</td>\n",
              "      <td>0.435565</td>\n",
              "      <td>0.662235</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-361.175537</td>\n",
              "      <td>41.273636</td>\n",
              "      <td>83.843750</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.843750</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>0.000242</td>\n",
              "      <td>0.723958</td>\n",
              "      <td>0.218977</td>\n",
              "      <td>-363.500000</td>\n",
              "      <td>67.466599</td>\n",
              "      <td>0.194246</td>\n",
              "      <td>0.733047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-358.332336</td>\n",
              "      <td>47.689278</td>\n",
              "      <td>80.406250</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80.406250</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>0.000230</td>\n",
              "      <td>0.728869</td>\n",
              "      <td>0.283464</td>\n",
              "      <td>-360.687500</td>\n",
              "      <td>102.924477</td>\n",
              "      <td>0.282515</td>\n",
              "      <td>0.594081</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-389.793365</td>\n",
              "      <td>83.864288</td>\n",
              "      <td>90.656250</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>90.656250</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>190.000000</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.733929</td>\n",
              "      <td>0.186336</td>\n",
              "      <td>-392.125000</td>\n",
              "      <td>135.890793</td>\n",
              "      <td>0.128964</td>\n",
              "      <td>0.719900</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-319.035858</td>\n",
              "      <td>45.058937</td>\n",
              "      <td>73.031250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.031250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.829613</td>\n",
              "      <td>0.276766</td>\n",
              "      <td>-321.687500</td>\n",
              "      <td>67.933762</td>\n",
              "      <td>0.290774</td>\n",
              "      <td>0.707017</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-323.622162</td>\n",
              "      <td>46.415184</td>\n",
              "      <td>73.406250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.406250</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>97.000000</td>\n",
              "      <td>0.000578</td>\n",
              "      <td>0.806994</td>\n",
              "      <td>0.267904</td>\n",
              "      <td>-326.500000</td>\n",
              "      <td>59.708969</td>\n",
              "      <td>0.414583</td>\n",
              "      <td>0.656549</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-393.055969</td>\n",
              "      <td>25.757139</td>\n",
              "      <td>92.875000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>92.875000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.884375</td>\n",
              "      <td>0.120263</td>\n",
              "      <td>-395.375000</td>\n",
              "      <td>44.290646</td>\n",
              "      <td>-0.065352</td>\n",
              "      <td>0.679220</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>-366.167603</td>\n",
              "      <td>55.824120</td>\n",
              "      <td>83.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>83.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>119.000000</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.766964</td>\n",
              "      <td>0.229903</td>\n",
              "      <td>-368.687500</td>\n",
              "      <td>93.408035</td>\n",
              "      <td>0.221677</td>\n",
              "      <td>0.718840</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>-347.303345</td>\n",
              "      <td>47.152485</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>0.001700</td>\n",
              "      <td>0.887723</td>\n",
              "      <td>0.215380</td>\n",
              "      <td>-349.875000</td>\n",
              "      <td>68.679596</td>\n",
              "      <td>0.402679</td>\n",
              "      <td>0.680496</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.281250</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>-408.844269</td>\n",
              "      <td>97.354980</td>\n",
              "      <td>93.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.799107</td>\n",
              "      <td>0.223821</td>\n",
              "      <td>-410.812500</td>\n",
              "      <td>126.347046</td>\n",
              "      <td>0.012872</td>\n",
              "      <td>0.606692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156250</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>-387.325806</td>\n",
              "      <td>32.735607</td>\n",
              "      <td>93.187500</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>93.187500</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.004250</td>\n",
              "      <td>0.836310</td>\n",
              "      <td>0.170598</td>\n",
              "      <td>-389.750000</td>\n",
              "      <td>72.010307</td>\n",
              "      <td>0.181631</td>\n",
              "      <td>0.632027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>-351.924133</td>\n",
              "      <td>80.526703</td>\n",
              "      <td>81.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.007975</td>\n",
              "      <td>0.841369</td>\n",
              "      <td>0.207536</td>\n",
              "      <td>-354.187500</td>\n",
              "      <td>102.150246</td>\n",
              "      <td>-0.015526</td>\n",
              "      <td>0.785509</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.504016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>-318.683655</td>\n",
              "      <td>40.785744</td>\n",
              "      <td>75.531250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.531250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>121.000000</td>\n",
              "      <td>0.007395</td>\n",
              "      <td>0.726562</td>\n",
              "      <td>0.345198</td>\n",
              "      <td>-320.687500</td>\n",
              "      <td>82.030060</td>\n",
              "      <td>-0.066468</td>\n",
              "      <td>0.606861</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>-333.286865</td>\n",
              "      <td>67.306236</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>0.011258</td>\n",
              "      <td>0.771949</td>\n",
              "      <td>0.220347</td>\n",
              "      <td>-335.437500</td>\n",
              "      <td>73.196571</td>\n",
              "      <td>0.066171</td>\n",
              "      <td>0.772017</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>-300.266052</td>\n",
              "      <td>62.993515</td>\n",
              "      <td>73.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>73.625000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>0.019919</td>\n",
              "      <td>0.821987</td>\n",
              "      <td>0.232437</td>\n",
              "      <td>-302.562500</td>\n",
              "      <td>77.631447</td>\n",
              "      <td>-0.025534</td>\n",
              "      <td>0.581997</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>-269.010925</td>\n",
              "      <td>64.293045</td>\n",
              "      <td>61.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>0.024653</td>\n",
              "      <td>0.684896</td>\n",
              "      <td>0.294738</td>\n",
              "      <td>-271.750000</td>\n",
              "      <td>79.174370</td>\n",
              "      <td>0.460417</td>\n",
              "      <td>0.655467</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.003500</td>\n",
              "      <td>-287.230347</td>\n",
              "      <td>59.734077</td>\n",
              "      <td>72.218750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>72.218750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>112.000000</td>\n",
              "      <td>0.034609</td>\n",
              "      <td>0.826711</td>\n",
              "      <td>0.260763</td>\n",
              "      <td>-289.250000</td>\n",
              "      <td>79.522362</td>\n",
              "      <td>-0.213294</td>\n",
              "      <td>0.736159</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.005300</td>\n",
              "      <td>-307.585846</td>\n",
              "      <td>44.848591</td>\n",
              "      <td>78.906250</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>78.906250</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>0.053146</td>\n",
              "      <td>0.821577</td>\n",
              "      <td>0.407107</td>\n",
              "      <td>-309.875000</td>\n",
              "      <td>56.771046</td>\n",
              "      <td>0.155084</td>\n",
              "      <td>0.637954</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>-274.192810</td>\n",
              "      <td>55.671822</td>\n",
              "      <td>66.750000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>66.750000</td>\n",
              "      <td>47.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.050295</td>\n",
              "      <td>0.817634</td>\n",
              "      <td>0.163480</td>\n",
              "      <td>-276.437500</td>\n",
              "      <td>55.485504</td>\n",
              "      <td>0.114583</td>\n",
              "      <td>0.532791</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>-263.637421</td>\n",
              "      <td>34.858665</td>\n",
              "      <td>67.093750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>67.093750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>103.000000</td>\n",
              "      <td>0.060309</td>\n",
              "      <td>0.731399</td>\n",
              "      <td>0.325593</td>\n",
              "      <td>-265.937500</td>\n",
              "      <td>94.300117</td>\n",
              "      <td>0.068676</td>\n",
              "      <td>0.719400</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>-252.951355</td>\n",
              "      <td>29.051928</td>\n",
              "      <td>65.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>65.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.050705</td>\n",
              "      <td>0.750893</td>\n",
              "      <td>0.291365</td>\n",
              "      <td>-255.125000</td>\n",
              "      <td>75.488838</td>\n",
              "      <td>0.110268</td>\n",
              "      <td>0.550568</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.006100</td>\n",
              "      <td>-242.685196</td>\n",
              "      <td>49.566204</td>\n",
              "      <td>62.156250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>62.156250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.060854</td>\n",
              "      <td>0.776339</td>\n",
              "      <td>0.310868</td>\n",
              "      <td>-245.000000</td>\n",
              "      <td>75.850449</td>\n",
              "      <td>-0.086533</td>\n",
              "      <td>0.743955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.009200</td>\n",
              "      <td>-227.369568</td>\n",
              "      <td>41.838310</td>\n",
              "      <td>58.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>58.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.091895</td>\n",
              "      <td>0.790625</td>\n",
              "      <td>0.321291</td>\n",
              "      <td>-229.750000</td>\n",
              "      <td>67.978645</td>\n",
              "      <td>0.246057</td>\n",
              "      <td>0.695842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>-263.177155</td>\n",
              "      <td>32.564606</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.132940</td>\n",
              "      <td>0.764137</td>\n",
              "      <td>0.348214</td>\n",
              "      <td>-265.125000</td>\n",
              "      <td>65.873657</td>\n",
              "      <td>-0.222545</td>\n",
              "      <td>0.662621</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>-238.955353</td>\n",
              "      <td>31.001371</td>\n",
              "      <td>60.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.050032</td>\n",
              "      <td>0.790774</td>\n",
              "      <td>0.261054</td>\n",
              "      <td>-240.937500</td>\n",
              "      <td>58.682270</td>\n",
              "      <td>-0.027381</td>\n",
              "      <td>0.701569</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.218750</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>-243.857971</td>\n",
              "      <td>18.289907</td>\n",
              "      <td>63.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>0.079812</td>\n",
              "      <td>0.762128</td>\n",
              "      <td>0.254899</td>\n",
              "      <td>-246.000000</td>\n",
              "      <td>71.105553</td>\n",
              "      <td>0.036161</td>\n",
              "      <td>0.634623</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343750</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.007600</td>\n",
              "      <td>-238.666534</td>\n",
              "      <td>47.237808</td>\n",
              "      <td>60.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.075758</td>\n",
              "      <td>0.770536</td>\n",
              "      <td>0.299439</td>\n",
              "      <td>-240.750000</td>\n",
              "      <td>63.611217</td>\n",
              "      <td>-0.062054</td>\n",
              "      <td>0.618580</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.008600</td>\n",
              "      <td>-188.071136</td>\n",
              "      <td>23.403349</td>\n",
              "      <td>47.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.937500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.086587</td>\n",
              "      <td>0.574107</td>\n",
              "      <td>0.355244</td>\n",
              "      <td>-190.812500</td>\n",
              "      <td>75.437408</td>\n",
              "      <td>0.292262</td>\n",
              "      <td>0.747300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.336011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>-247.865479</td>\n",
              "      <td>35.780403</td>\n",
              "      <td>64.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.057375</td>\n",
              "      <td>0.830208</td>\n",
              "      <td>0.299864</td>\n",
              "      <td>-250.000000</td>\n",
              "      <td>67.533501</td>\n",
              "      <td>-0.195685</td>\n",
              "      <td>0.667287</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.007100</td>\n",
              "      <td>-248.465332</td>\n",
              "      <td>23.275635</td>\n",
              "      <td>64.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>64.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>0.071308</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.242452</td>\n",
              "      <td>-250.312500</td>\n",
              "      <td>61.209545</td>\n",
              "      <td>-0.371577</td>\n",
              "      <td>0.641027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.406250</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.010400</td>\n",
              "      <td>-251.779694</td>\n",
              "      <td>99.718979</td>\n",
              "      <td>60.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>56.161289</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.103940</td>\n",
              "      <td>0.706324</td>\n",
              "      <td>0.331968</td>\n",
              "      <td>-254.375000</td>\n",
              "      <td>195.331604</td>\n",
              "      <td>0.138988</td>\n",
              "      <td>0.747670</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.176777</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>-234.801849</td>\n",
              "      <td>17.718575</td>\n",
              "      <td>61.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>61.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.060180</td>\n",
              "      <td>0.701786</td>\n",
              "      <td>0.368798</td>\n",
              "      <td>-237.312500</td>\n",
              "      <td>80.792221</td>\n",
              "      <td>0.152604</td>\n",
              "      <td>0.758956</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>-225.473892</td>\n",
              "      <td>38.504852</td>\n",
              "      <td>56.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>0.101528</td>\n",
              "      <td>0.634226</td>\n",
              "      <td>0.320625</td>\n",
              "      <td>-227.812500</td>\n",
              "      <td>106.531670</td>\n",
              "      <td>0.110640</td>\n",
              "      <td>0.757577</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.022900</td>\n",
              "      <td>-206.438019</td>\n",
              "      <td>42.956593</td>\n",
              "      <td>52.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.229227</td>\n",
              "      <td>0.654018</td>\n",
              "      <td>0.344063</td>\n",
              "      <td>-209.187500</td>\n",
              "      <td>74.805313</td>\n",
              "      <td>0.282961</td>\n",
              "      <td>0.744770</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.396558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.014100</td>\n",
              "      <td>-195.656067</td>\n",
              "      <td>19.162525</td>\n",
              "      <td>50.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.140759</td>\n",
              "      <td>0.612165</td>\n",
              "      <td>0.374031</td>\n",
              "      <td>-198.312500</td>\n",
              "      <td>81.676163</td>\n",
              "      <td>0.450521</td>\n",
              "      <td>0.706331</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.009900</td>\n",
              "      <td>-200.227524</td>\n",
              "      <td>17.835083</td>\n",
              "      <td>51.281250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51.281250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.099347</td>\n",
              "      <td>0.587054</td>\n",
              "      <td>0.304830</td>\n",
              "      <td>-202.375000</td>\n",
              "      <td>76.912079</td>\n",
              "      <td>0.060417</td>\n",
              "      <td>0.690719</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.015500</td>\n",
              "      <td>-164.676453</td>\n",
              "      <td>11.209517</td>\n",
              "      <td>41.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.500000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.155185</td>\n",
              "      <td>0.485007</td>\n",
              "      <td>0.395664</td>\n",
              "      <td>-167.437500</td>\n",
              "      <td>66.565971</td>\n",
              "      <td>0.432292</td>\n",
              "      <td>0.710570</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.010600</td>\n",
              "      <td>-197.617249</td>\n",
              "      <td>40.895222</td>\n",
              "      <td>50.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>0.105600</td>\n",
              "      <td>0.478125</td>\n",
              "      <td>0.432894</td>\n",
              "      <td>-199.937500</td>\n",
              "      <td>78.663811</td>\n",
              "      <td>0.310863</td>\n",
              "      <td>0.712224</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.531250</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.016300</td>\n",
              "      <td>-174.884308</td>\n",
              "      <td>37.108330</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.163142</td>\n",
              "      <td>0.456324</td>\n",
              "      <td>0.412214</td>\n",
              "      <td>-177.437500</td>\n",
              "      <td>72.569847</td>\n",
              "      <td>0.471875</td>\n",
              "      <td>0.795016</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.016500</td>\n",
              "      <td>-127.473511</td>\n",
              "      <td>8.358686</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.164987</td>\n",
              "      <td>0.234821</td>\n",
              "      <td>0.172205</td>\n",
              "      <td>-130.250000</td>\n",
              "      <td>37.363945</td>\n",
              "      <td>0.760417</td>\n",
              "      <td>0.559021</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>-224.423523</td>\n",
              "      <td>34.373291</td>\n",
              "      <td>56.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>56.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>0.124413</td>\n",
              "      <td>0.705655</td>\n",
              "      <td>0.367661</td>\n",
              "      <td>-226.812500</td>\n",
              "      <td>77.841621</td>\n",
              "      <td>0.027083</td>\n",
              "      <td>0.736775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>-198.788300</td>\n",
              "      <td>30.215858</td>\n",
              "      <td>51.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>51.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.160574</td>\n",
              "      <td>0.573214</td>\n",
              "      <td>0.359019</td>\n",
              "      <td>-201.625000</td>\n",
              "      <td>80.309784</td>\n",
              "      <td>0.450992</td>\n",
              "      <td>0.677362</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.396558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.012700</td>\n",
              "      <td>-174.657364</td>\n",
              "      <td>32.463898</td>\n",
              "      <td>43.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.127002</td>\n",
              "      <td>0.580134</td>\n",
              "      <td>0.386269</td>\n",
              "      <td>-177.437500</td>\n",
              "      <td>62.781204</td>\n",
              "      <td>0.481250</td>\n",
              "      <td>0.689654</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.017500</td>\n",
              "      <td>-168.368973</td>\n",
              "      <td>29.651026</td>\n",
              "      <td>41.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>0.174743</td>\n",
              "      <td>0.484821</td>\n",
              "      <td>0.352998</td>\n",
              "      <td>-171.250000</td>\n",
              "      <td>86.030373</td>\n",
              "      <td>0.614955</td>\n",
              "      <td>0.609121</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>-184.249557</td>\n",
              "      <td>40.474663</td>\n",
              "      <td>46.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.875000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.187385</td>\n",
              "      <td>0.440104</td>\n",
              "      <td>0.406012</td>\n",
              "      <td>-186.687500</td>\n",
              "      <td>83.514122</td>\n",
              "      <td>0.279092</td>\n",
              "      <td>0.774404</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.018000</td>\n",
              "      <td>-193.692413</td>\n",
              "      <td>13.732149</td>\n",
              "      <td>49.343750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.343750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>0.179965</td>\n",
              "      <td>0.560938</td>\n",
              "      <td>0.338359</td>\n",
              "      <td>-195.625000</td>\n",
              "      <td>85.237335</td>\n",
              "      <td>-0.253348</td>\n",
              "      <td>0.880787</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.020300</td>\n",
              "      <td>-167.929764</td>\n",
              "      <td>28.431206</td>\n",
              "      <td>42.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>42.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.203304</td>\n",
              "      <td>0.434821</td>\n",
              "      <td>0.328770</td>\n",
              "      <td>-170.187500</td>\n",
              "      <td>76.513306</td>\n",
              "      <td>0.229167</td>\n",
              "      <td>0.765705</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.018600</td>\n",
              "      <td>-136.154022</td>\n",
              "      <td>8.561239</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.186198</td>\n",
              "      <td>0.283482</td>\n",
              "      <td>0.239702</td>\n",
              "      <td>-138.687500</td>\n",
              "      <td>44.743309</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.589134</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.504016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.023000</td>\n",
              "      <td>-196.817047</td>\n",
              "      <td>41.358147</td>\n",
              "      <td>50.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>0.230103</td>\n",
              "      <td>0.504055</td>\n",
              "      <td>0.382585</td>\n",
              "      <td>-199.062500</td>\n",
              "      <td>108.267273</td>\n",
              "      <td>0.272656</td>\n",
              "      <td>0.801229</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>-175.491074</td>\n",
              "      <td>25.317871</td>\n",
              "      <td>44.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.172673</td>\n",
              "      <td>0.493452</td>\n",
              "      <td>0.369110</td>\n",
              "      <td>-177.937500</td>\n",
              "      <td>72.333427</td>\n",
              "      <td>0.390476</td>\n",
              "      <td>0.719726</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.504016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.021400</td>\n",
              "      <td>-176.931915</td>\n",
              "      <td>24.516493</td>\n",
              "      <td>44.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.214477</td>\n",
              "      <td>0.495164</td>\n",
              "      <td>0.362843</td>\n",
              "      <td>-179.625000</td>\n",
              "      <td>77.971771</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.617151</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>-136.369354</td>\n",
              "      <td>25.195387</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.259538</td>\n",
              "      <td>0.307440</td>\n",
              "      <td>0.280816</td>\n",
              "      <td>-139.125000</td>\n",
              "      <td>51.250019</td>\n",
              "      <td>0.604464</td>\n",
              "      <td>0.723529</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>-147.865631</td>\n",
              "      <td>0.086603</td>\n",
              "      <td>36.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.226214</td>\n",
              "      <td>0.342708</td>\n",
              "      <td>0.256857</td>\n",
              "      <td>-150.500000</td>\n",
              "      <td>62.965427</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.647465</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>-125.814285</td>\n",
              "      <td>25.237572</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.340061</td>\n",
              "      <td>0.246131</td>\n",
              "      <td>0.235296</td>\n",
              "      <td>-128.687500</td>\n",
              "      <td>46.252068</td>\n",
              "      <td>0.845833</td>\n",
              "      <td>0.472145</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.027800</td>\n",
              "      <td>-190.977676</td>\n",
              "      <td>25.730785</td>\n",
              "      <td>47.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>47.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>93.000000</td>\n",
              "      <td>0.278481</td>\n",
              "      <td>0.520685</td>\n",
              "      <td>0.306113</td>\n",
              "      <td>-193.000000</td>\n",
              "      <td>71.755859</td>\n",
              "      <td>0.064137</td>\n",
              "      <td>0.796491</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.504016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.017400</td>\n",
              "      <td>-158.655945</td>\n",
              "      <td>15.304176</td>\n",
              "      <td>39.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>39.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.173505</td>\n",
              "      <td>0.431548</td>\n",
              "      <td>0.327508</td>\n",
              "      <td>-161.500000</td>\n",
              "      <td>64.797447</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.520546</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.396558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>-207.235626</td>\n",
              "      <td>40.786430</td>\n",
              "      <td>52.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>52.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.206995</td>\n",
              "      <td>0.599033</td>\n",
              "      <td>0.373271</td>\n",
              "      <td>-209.500000</td>\n",
              "      <td>86.676262</td>\n",
              "      <td>0.196577</td>\n",
              "      <td>0.882221</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.468750</td>\n",
              "      <td>0.507007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>-189.113678</td>\n",
              "      <td>29.830507</td>\n",
              "      <td>48.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>48.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.139809</td>\n",
              "      <td>0.599107</td>\n",
              "      <td>0.374534</td>\n",
              "      <td>-191.875000</td>\n",
              "      <td>67.393761</td>\n",
              "      <td>0.443452</td>\n",
              "      <td>0.679262</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>-151.031998</td>\n",
              "      <td>23.553240</td>\n",
              "      <td>37.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.250000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.274537</td>\n",
              "      <td>0.415923</td>\n",
              "      <td>0.376971</td>\n",
              "      <td>-153.625000</td>\n",
              "      <td>64.210213</td>\n",
              "      <td>0.395833</td>\n",
              "      <td>0.791702</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.023500</td>\n",
              "      <td>-131.854538</td>\n",
              "      <td>20.487511</td>\n",
              "      <td>31.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.750000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.234989</td>\n",
              "      <td>0.274926</td>\n",
              "      <td>0.214858</td>\n",
              "      <td>-134.562500</td>\n",
              "      <td>40.941292</td>\n",
              "      <td>0.589286</td>\n",
              "      <td>0.764756</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.022600</td>\n",
              "      <td>-130.824036</td>\n",
              "      <td>11.165015</td>\n",
              "      <td>31.343750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.343750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.226335</td>\n",
              "      <td>0.327009</td>\n",
              "      <td>0.312920</td>\n",
              "      <td>-133.687500</td>\n",
              "      <td>40.757690</td>\n",
              "      <td>0.630208</td>\n",
              "      <td>0.677565</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.296145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.031300</td>\n",
              "      <td>-136.511169</td>\n",
              "      <td>38.203522</td>\n",
              "      <td>33.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.312843</td>\n",
              "      <td>0.303423</td>\n",
              "      <td>0.305367</td>\n",
              "      <td>-139.000000</td>\n",
              "      <td>56.504639</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.812624</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.025500</td>\n",
              "      <td>-121.861534</td>\n",
              "      <td>6.251237</td>\n",
              "      <td>29.093750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.093750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.254730</td>\n",
              "      <td>0.263467</td>\n",
              "      <td>0.240613</td>\n",
              "      <td>-124.687500</td>\n",
              "      <td>26.691109</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.593328</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.013300</td>\n",
              "      <td>-179.670609</td>\n",
              "      <td>14.732519</td>\n",
              "      <td>45.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.132725</td>\n",
              "      <td>0.488988</td>\n",
              "      <td>0.346467</td>\n",
              "      <td>-182.375000</td>\n",
              "      <td>81.831352</td>\n",
              "      <td>0.559152</td>\n",
              "      <td>0.700440</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656250</td>\n",
              "      <td>0.482559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.033400</td>\n",
              "      <td>-139.408417</td>\n",
              "      <td>19.981094</td>\n",
              "      <td>33.406250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.406250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.333644</td>\n",
              "      <td>0.349405</td>\n",
              "      <td>0.309608</td>\n",
              "      <td>-142.625000</td>\n",
              "      <td>56.989952</td>\n",
              "      <td>0.929688</td>\n",
              "      <td>0.354887</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.245935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>-134.460724</td>\n",
              "      <td>2.550719</td>\n",
              "      <td>32.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.187500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.163690</td>\n",
              "      <td>0.292262</td>\n",
              "      <td>0.248141</td>\n",
              "      <td>-137.000000</td>\n",
              "      <td>57.563427</td>\n",
              "      <td>0.747024</td>\n",
              "      <td>0.606024</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.508000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.059300</td>\n",
              "      <td>-131.285706</td>\n",
              "      <td>7.839287</td>\n",
              "      <td>31.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.625000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.593347</td>\n",
              "      <td>0.301786</td>\n",
              "      <td>0.287477</td>\n",
              "      <td>-134.125000</td>\n",
              "      <td>45.973167</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.507842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.439941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.025500</td>\n",
              "      <td>-148.963104</td>\n",
              "      <td>27.920187</td>\n",
              "      <td>36.718750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>36.718750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.255395</td>\n",
              "      <td>0.396280</td>\n",
              "      <td>0.323808</td>\n",
              "      <td>-151.687500</td>\n",
              "      <td>58.796772</td>\n",
              "      <td>0.578125</td>\n",
              "      <td>0.690416</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.439941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.033000</td>\n",
              "      <td>-134.643234</td>\n",
              "      <td>10.222744</td>\n",
              "      <td>32.468750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.468750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.329604</td>\n",
              "      <td>0.305134</td>\n",
              "      <td>0.269520</td>\n",
              "      <td>-137.187500</td>\n",
              "      <td>50.132362</td>\n",
              "      <td>0.395387</td>\n",
              "      <td>0.860396</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.035400</td>\n",
              "      <td>-128.920990</td>\n",
              "      <td>13.532810</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.354123</td>\n",
              "      <td>0.266518</td>\n",
              "      <td>0.168352</td>\n",
              "      <td>-131.062500</td>\n",
              "      <td>32.559563</td>\n",
              "      <td>0.031250</td>\n",
              "      <td>0.931755</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.021800</td>\n",
              "      <td>-156.467865</td>\n",
              "      <td>29.360815</td>\n",
              "      <td>38.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.218075</td>\n",
              "      <td>0.414583</td>\n",
              "      <td>0.353927</td>\n",
              "      <td>-159.437500</td>\n",
              "      <td>68.180473</td>\n",
              "      <td>0.773810</td>\n",
              "      <td>0.501625</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.024500</td>\n",
              "      <td>-121.915771</td>\n",
              "      <td>14.709948</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.244701</td>\n",
              "      <td>0.213690</td>\n",
              "      <td>0.191188</td>\n",
              "      <td>-124.875000</td>\n",
              "      <td>42.289135</td>\n",
              "      <td>0.808036</td>\n",
              "      <td>0.542602</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.245935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.021600</td>\n",
              "      <td>-162.441223</td>\n",
              "      <td>58.181229</td>\n",
              "      <td>37.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.781250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>144.000000</td>\n",
              "      <td>0.215610</td>\n",
              "      <td>0.399405</td>\n",
              "      <td>0.370755</td>\n",
              "      <td>-165.062500</td>\n",
              "      <td>130.327606</td>\n",
              "      <td>0.503125</td>\n",
              "      <td>0.747246</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.027800</td>\n",
              "      <td>-123.134079</td>\n",
              "      <td>7.989583</td>\n",
              "      <td>28.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.812500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.277988</td>\n",
              "      <td>0.225298</td>\n",
              "      <td>0.148720</td>\n",
              "      <td>-125.562500</td>\n",
              "      <td>27.454287</td>\n",
              "      <td>0.328125</td>\n",
              "      <td>0.903482</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.336011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>-115.779694</td>\n",
              "      <td>5.681544</td>\n",
              "      <td>26.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.843750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.347747</td>\n",
              "      <td>0.235938</td>\n",
              "      <td>0.144747</td>\n",
              "      <td>-118.562500</td>\n",
              "      <td>16.834944</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.790410</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.245935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.026800</td>\n",
              "      <td>-137.765854</td>\n",
              "      <td>41.844223</td>\n",
              "      <td>33.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.267890</td>\n",
              "      <td>0.278795</td>\n",
              "      <td>0.255426</td>\n",
              "      <td>-140.375000</td>\n",
              "      <td>62.859673</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.757669</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.027200</td>\n",
              "      <td>-135.635269</td>\n",
              "      <td>32.128345</td>\n",
              "      <td>33.031250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.031250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.272469</td>\n",
              "      <td>0.345982</td>\n",
              "      <td>0.335664</td>\n",
              "      <td>-138.437500</td>\n",
              "      <td>49.432217</td>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.676103</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.031700</td>\n",
              "      <td>-172.158325</td>\n",
              "      <td>37.183861</td>\n",
              "      <td>41.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>0.317129</td>\n",
              "      <td>0.445833</td>\n",
              "      <td>0.387236</td>\n",
              "      <td>-174.562500</td>\n",
              "      <td>96.002998</td>\n",
              "      <td>0.208333</td>\n",
              "      <td>0.896629</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.439941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.033600</td>\n",
              "      <td>-127.656395</td>\n",
              "      <td>24.301538</td>\n",
              "      <td>30.718750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.718750</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.336088</td>\n",
              "      <td>0.257143</td>\n",
              "      <td>0.209805</td>\n",
              "      <td>-130.375000</td>\n",
              "      <td>51.150471</td>\n",
              "      <td>0.617708</td>\n",
              "      <td>0.751581</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.024600</td>\n",
              "      <td>-144.336014</td>\n",
              "      <td>23.776842</td>\n",
              "      <td>35.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.246055</td>\n",
              "      <td>0.298363</td>\n",
              "      <td>0.251875</td>\n",
              "      <td>-146.750000</td>\n",
              "      <td>55.378464</td>\n",
              "      <td>0.490625</td>\n",
              "      <td>0.819311</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.028500</td>\n",
              "      <td>-135.362350</td>\n",
              "      <td>22.164572</td>\n",
              "      <td>33.031250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.031250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.285185</td>\n",
              "      <td>0.296280</td>\n",
              "      <td>0.282735</td>\n",
              "      <td>-138.062500</td>\n",
              "      <td>58.626171</td>\n",
              "      <td>0.716369</td>\n",
              "      <td>0.618202</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.470929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.019900</td>\n",
              "      <td>-136.595535</td>\n",
              "      <td>7.763275</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.198774</td>\n",
              "      <td>0.304464</td>\n",
              "      <td>0.297253</td>\n",
              "      <td>-139.625000</td>\n",
              "      <td>55.468533</td>\n",
              "      <td>0.818750</td>\n",
              "      <td>0.512562</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>0.296145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.024800</td>\n",
              "      <td>-117.509224</td>\n",
              "      <td>11.857143</td>\n",
              "      <td>27.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.687500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.248120</td>\n",
              "      <td>0.196131</td>\n",
              "      <td>0.151060</td>\n",
              "      <td>-120.562500</td>\n",
              "      <td>32.777782</td>\n",
              "      <td>0.919643</td>\n",
              "      <td>0.364554</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.245935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.034500</td>\n",
              "      <td>-150.046509</td>\n",
              "      <td>46.227875</td>\n",
              "      <td>34.468750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>34.468750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.344687</td>\n",
              "      <td>0.273810</td>\n",
              "      <td>0.232106</td>\n",
              "      <td>-153.062500</td>\n",
              "      <td>114.817078</td>\n",
              "      <td>0.773438</td>\n",
              "      <td>0.620092</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.176777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.026200</td>\n",
              "      <td>-132.907211</td>\n",
              "      <td>16.138680</td>\n",
              "      <td>32.406250</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.406250</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.262228</td>\n",
              "      <td>0.306324</td>\n",
              "      <td>0.297072</td>\n",
              "      <td>-135.687500</td>\n",
              "      <td>49.584362</td>\n",
              "      <td>0.630208</td>\n",
              "      <td>0.687490</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>-121.825294</td>\n",
              "      <td>17.882282</td>\n",
              "      <td>28.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.437500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.275044</td>\n",
              "      <td>0.205952</td>\n",
              "      <td>0.121655</td>\n",
              "      <td>-124.250000</td>\n",
              "      <td>32.288017</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>0.913607</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.078900</td>\n",
              "      <td>-124.306915</td>\n",
              "      <td>26.460270</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.788976</td>\n",
              "      <td>0.215402</td>\n",
              "      <td>0.168822</td>\n",
              "      <td>-127.000000</td>\n",
              "      <td>52.680412</td>\n",
              "      <td>0.696429</td>\n",
              "      <td>0.718192</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.781250</td>\n",
              "      <td>0.420013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.026200</td>\n",
              "      <td>-123.623505</td>\n",
              "      <td>7.662799</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.375000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.261911</td>\n",
              "      <td>0.239583</td>\n",
              "      <td>0.162662</td>\n",
              "      <td>-126.437500</td>\n",
              "      <td>36.553925</td>\n",
              "      <td>0.699405</td>\n",
              "      <td>0.652296</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.336011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>-124.929016</td>\n",
              "      <td>11.791666</td>\n",
              "      <td>29.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.260290</td>\n",
              "      <td>0.266815</td>\n",
              "      <td>0.252545</td>\n",
              "      <td>-127.750000</td>\n",
              "      <td>38.318695</td>\n",
              "      <td>0.741667</td>\n",
              "      <td>0.585549</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.396558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.043200</td>\n",
              "      <td>-155.578125</td>\n",
              "      <td>36.743629</td>\n",
              "      <td>37.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.906250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>0.432424</td>\n",
              "      <td>0.423958</td>\n",
              "      <td>0.325167</td>\n",
              "      <td>-158.187500</td>\n",
              "      <td>64.398674</td>\n",
              "      <td>0.435417</td>\n",
              "      <td>0.787898</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.439941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.027900</td>\n",
              "      <td>-155.606247</td>\n",
              "      <td>46.462490</td>\n",
              "      <td>38.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.593750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>0.279146</td>\n",
              "      <td>0.351786</td>\n",
              "      <td>0.325721</td>\n",
              "      <td>-158.125000</td>\n",
              "      <td>75.312576</td>\n",
              "      <td>0.323214</td>\n",
              "      <td>0.862811</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.368902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>-128.474854</td>\n",
              "      <td>2.308864</td>\n",
              "      <td>30.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.562500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>0.220308</td>\n",
              "      <td>0.272024</td>\n",
              "      <td>0.206751</td>\n",
              "      <td>-131.312500</td>\n",
              "      <td>45.404587</td>\n",
              "      <td>0.815625</td>\n",
              "      <td>0.509338</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.439941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.033200</td>\n",
              "      <td>-126.134224</td>\n",
              "      <td>23.515114</td>\n",
              "      <td>30.218750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.218750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>0.332206</td>\n",
              "      <td>0.259524</td>\n",
              "      <td>0.224781</td>\n",
              "      <td>-128.875000</td>\n",
              "      <td>40.244213</td>\n",
              "      <td>0.762500</td>\n",
              "      <td>0.575158</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.718750</td>\n",
              "      <td>0.456803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.024700</td>\n",
              "      <td>-148.216522</td>\n",
              "      <td>17.481752</td>\n",
              "      <td>35.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>35.656250</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>0.246524</td>\n",
              "      <td>0.385565</td>\n",
              "      <td>0.314269</td>\n",
              "      <td>-150.625000</td>\n",
              "      <td>59.886856</td>\n",
              "      <td>0.429167</td>\n",
              "      <td>0.816924</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.593750</td>\n",
              "      <td>0.498991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.022400</td>\n",
              "      <td>-111.561157</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.223642</td>\n",
              "      <td>0.188839</td>\n",
              "      <td>0.045662</td>\n",
              "      <td>-114.750000</td>\n",
              "      <td>2.016064</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.029200</td>\n",
              "      <td>-117.805435</td>\n",
              "      <td>6.005725</td>\n",
              "      <td>27.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.968750</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>0.292416</td>\n",
              "      <td>0.241443</td>\n",
              "      <td>0.212136</td>\n",
              "      <td>-120.875000</td>\n",
              "      <td>24.245718</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.485423</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.030200</td>\n",
              "      <td>-112.457886</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>0.302144</td>\n",
              "      <td>0.167113</td>\n",
              "      <td>0.038506</td>\n",
              "      <td>-114.937500</td>\n",
              "      <td>2.638884</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.737804</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.491869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>-127.195160</td>\n",
              "      <td>28.963669</td>\n",
              "      <td>29.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>29.312500</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>0.347706</td>\n",
              "      <td>0.231920</td>\n",
              "      <td>0.127867</td>\n",
              "      <td>-129.875000</td>\n",
              "      <td>56.873230</td>\n",
              "      <td>0.572917</td>\n",
              "      <td>0.821897</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.336011</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"absolve\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 1 so far\n",
            "4. a - 1 so far\n",
            "5. b - 1 so far\n",
            "6. o - 2 so far\n",
            "7. l - 2 so far\n",
            "8. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"crave\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of r's in the word crave\n",
            "1. c - 0 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 from previous count, now 1 so far\n",
            "4. v - 1 from previous count, now 1 so far\n",
            "5. e - 1 from previous count, now 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"absolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of v's in the word absolve\n",
            "1. a - 0 so far\n",
            "2. b - 0 so far\n",
            "3. s - 0 so far\n",
            "4. o - 0 so far\n",
            "5. v - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of e's in the word echo\n",
            "1. e - 1 so far\n",
            "2. c - 1 so far\n",
            "3. h - 1 so far\n",
            "4. o - 1 so far\n",
            "5. c - 2 so far\n",
            "6. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of o's in the word ivory\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. o - 0 so far\n",
            "4. i - 1 so far\n",
            "5. v - 1 so far\n",
            "6. r - 1 so far\n",
            "7. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of m's in the word \"fume\"\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"frescos\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of f's in the word frescos\n",
            "1. f - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. s - 2 so far\n",
            "5. c - 2 so far\n",
            "6. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"capture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of l's in the word capture\n",
            "1. c - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. u - 2 so far\n",
            "5. b - 2 so far\n",
            "6. a - 2 so far\n",
            "7. c - 2 so far\n",
            "8. e - 3 so far\n",
            "9. r - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"knack\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "Counting the number of k's in the word knack\n",
            "1. k - 1 so far\n",
            "2. n - 1 still (not a k)\n",
            "3. a - 1 still (not a k)\n",
            "4. k - 2 so far\n",
            "5. c - 2 still (not a k)\n",
            "6. k - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"zealous\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of k's in the word \"zealous\"\n",
            "1. z - 0 so far\n",
            "2. e - 1 so far\n",
            "3. a - 2 so far\n",
            "4. l - 3 so far\n",
            "5. o - 4 so far\n",
            "6. u - 5 so far\n",
            "7. s - 6 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of t's in the word tavern\n",
            "1. t - 1 so far\n",
            "2. a - 1 so far\n",
            "3. v - 1 so far\n",
            "4. e - 1 so far\n",
            "5. n - 1 so far\n",
            "6. t - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of a's in the word mantle\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. a - 2 so far\n",
            "5. l - 2 so far\n",
            "6. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "Counting the number of l's in the word torrent\n",
            "1. t - 0 so far\n",
            "2. o - 1 so far\n",
            "3. r - 2 so far\n",
            "4. o - 3 so far\n",
            "5. t - 4 so far\n",
            "6. a - 4 so far\n",
            "7. n - 5 so far\n",
            "6.\n",
            "There is no 'l' in the word \"torrent\".\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of n's in the word fusion\n",
            "1. f - 0 so far\n",
            "2. u - 1 so far\n",
            "3. n - 1 so far\n",
            "4. s - 2 so far\n",
            "5. i - 3 so far\n",
            "6. o - 4 so far\n",
            "7. n - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"onset\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "2. n - 1 so far\n",
            "3. s - 1 so far\n",
            "4. e - 1 so far\n",
            "5. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "2. v - 0 so far\n",
            "3. r - 1 so far\n",
            "4. o - 1 so far\n",
            "5. y - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"whistle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. w - 0 so far\n",
            "2. h - 0 so far\n",
            "3. y - 0 so far\n",
            "4. s - 0 so far\n",
            "5. h - 0 so far\n",
            "6. t - 0 so far\n",
            "7. l - 0 so far\n",
            "8. e - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"mirage\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 0 so far\n",
            "2. i - 1 so far\n",
            "3. r - 0 so far\n",
            "4. a - 0 so far\n",
            "5. g - 0 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. a - 1 so far\n",
            "3. p - 1 so far\n",
            "4. a - 2 so far\n",
            "5. r - 2 so far\n",
            "6. a - 3 so far\n",
            "7. p - 4 so far\n",
            "8. h - 4 so far\n",
            "9. e - 4 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "4\n",
            "</answer>\n",
            "Extracted: 4\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"sapphire\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 0 so far\n",
            "2. i - 1 so far\n",
            "...\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"verge\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. r - 1 so far\n",
            "4. r - 2 so far\n",
            "5. g - 2 so far\n",
            "6. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"crisp\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "2. r - 0 so far\n",
            "3. i - 0 so far\n",
            "4. p - 0 so far\n",
            "5. s - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"y\" are there in the word \"fusion\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. f - 1 so far\n",
            "2. u - 1 so far\n",
            "3. s - 1 so far\n",
            "4. i - 1 so far\n",
            "5. o - 1 so far\n",
            "6. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"x\" are there in the word \"wisp\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. w - 0 so far\n",
            "2. i - 1 so far\n",
            "3. s - 1 so far\n",
            "4. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. l - 0 so far\n",
            "3. u - 0 so far\n",
            "4. d - 0 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "2. r - 1 so far\n",
            "3. a - 1 so far\n",
            "4. r - 2 so far\n",
            "5. d - 2 so far\n",
            "6. h - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 0 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. e - 0 so far (first time seeing 'e')\n",
            "5. l - 2 so far\n",
            "6. e - 1 so far (second time seeing 'e')\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"ivory\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "2. v - 0 so far\n",
            "3. o - 1 so far\n",
            "4. r - 0 so far\n",
            "5. y - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. p - 0 so far\n",
            "2. r - 0 so far\n",
            "3. e - 1 so far\n",
            "4. u - 1 so far\n",
            "5. l - 2 so far\n",
            "6. e - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "Extracted: 3\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"m\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"oath\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 0 so far\n",
            "2. a - 1 so far\n",
            "3. h - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 0 so far\n",
            "5. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"sapphire\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"mantle\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "2. a - 1 so far\n",
            "3. n - 1 so far\n",
            "4. t - 1 so far\n",
            "5. l - 1 so far\n",
            "6. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"veto\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. v - 0 so far\n",
            "2. e - 1 so far\n",
            "3. t - 1 so far\n",
            "4. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"resolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"orchard\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 0 so far\n",
            "2. r - 1 so far\n",
            "3. c - 1 so far\n",
            "4. h - 1 so far\n",
            "5. a - 2 so far\n",
            "6. r - 3 so far\n",
            "7. d - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"fathom\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"elude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"fusion\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"aperture\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "2. p - 0 so far\n",
            "3. u - 0 so far\n",
            "4. r - 0 so far\n",
            "5. e - 1 so far\n",
            "6. t - 1 so far\n",
            "7. e - 2 so far\n",
            "8. a - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"knack\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. k - 1 so far\n",
            "2. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"capture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"eclipse\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. e - 0 so far\n",
            "2. c - 0 so far\n",
            "3. l - 0 so far\n",
            "4. i - 0 so far\n",
            "5. p - 0 so far\n",
            "6. s - 0 so far\n",
            "7. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"elude\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. l - 0 so far\n",
            "3. u - 0 so far\n",
            "4. d - 0 so far\n",
            "5. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"n\" are there in the word \"enchant\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"aperture\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"banner\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"t\" are there in the word \"torrent\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"prelude\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"prelude\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"torrent\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. t - 1 so far\n",
            "2. o - 1 so far\n",
            "3. r - 1 so far\n",
            "4. v - 0 so far\n",
            "5. e - 1 so far\n",
            "6. a - 0 so far\n",
            "7. n - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"quest\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. q - 1 so far\n",
            "2. u - 0 so far\n",
            "3. e - 0 so far (first occurrence)\n",
            "4. s - 1 so far\n",
            "5. t - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"mosaic\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. m - 1 so far\n",
            "2. o - 1 so far\n",
            "3. a - 1 so far\n",
            "4. s - 1 so far\n",
            "5. a - 2 so far\n",
            "6. c - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"p\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"u\" are there in the word \"radius\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. u - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"resolve\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"gaze\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"gossipy\"\n",
            "Answer: 2\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"scarab\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "2. c - 1 so far\n",
            "3. a - 1 so far\n",
            "4. r - 1 so far\n",
            "5. b - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"relish\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 0 so far\n",
            "2. i - 1 so far\n",
            "3. s - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"sphinx\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. p - 0 so far\n",
            "3. h - 0 so far\n",
            "4. n - 0 so far\n",
            "5. f - 0 so far\n",
            "6. k - 0 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "0\n",
            "</answer>\n",
            "Extracted: 0\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"grim\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. m - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"cipher\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"cipher\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. r - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"a\" are there in the word \"tavern\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"ember\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. m - 0 so far\n",
            "3. b - 0 so far\n",
            "4. e - 1 (updating the count) so far\n",
            "5. m - 1 (updating the count) so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"zealous\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. s - 0 so far\n",
            "2. z - 1 so far\n",
            "3. e - 1 so far\n",
            "4. a - 1 so far\n",
            "5. l - 1 so far\n",
            "6. o - 1 so far\n",
            "7. u - 1 so far\n",
            "8. s - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"enchant\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"verge\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. v - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"e\" are there in the word \"cipher\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"r\" are there in the word \"prelude\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. p - 1 so far\n",
            "2. r - 1 so far\n",
            "3. e - 1 so far\n",
            "4. l - 1 so far\n",
            "5. u - 1 so far\n",
            "6. d - 1 so far\n",
            "7. e - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"u\" are there in the word \"prelude\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. u - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"l\" are there in the word \"glisten\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. l - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"o\" are there in the word \"expose\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. o - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"w\" are there in the word \"frescos\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. w - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"f\" are there in the word \"fume\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. f - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"b\" are there in the word \"ember\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. b - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"s\" are there in the word \"rust\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "Counting the number of s's in the word rust\n",
            "1. r - 0 so far\n",
            "2. u - 0 so far\n",
            "3. s - 1 so far\n",
            "4. t - 1 so far\n",
            "5. s - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"v\" are there in the word \"ivory\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "2. v - 1 so far\n",
            "3. o - 1 so far\n",
            "4. r - 1 so far\n",
            "5. y - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"h\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. h - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"u\" are there in the word \"lush\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. u - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"k\" are there in the word \"grim\"\n",
            "Answer: 0\n",
            "Response: <reasoning>\n",
            "1. g - 0 so far\n",
            "2. r - 1 so far\n",
            "3. i - 1 so far\n",
            "4. m - 2 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "2\n",
            "</answer>\n",
            "Extracted: 2\n",
            "Correct: False!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"triumph\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"c\" are there in the word \"echo\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. e - 1 so far\n",
            "2. c - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"summit\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "\n",
            "--------------------\n",
            "Question: How many of the letter \"i\" are there in the word \"eclipse\"\n",
            "Answer: 1\n",
            "Response: <reasoning>\n",
            "1. i - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "Extracted: 1\n",
            "Correct: True!\n",
            "    \n",
            "time: 27min 45s (started: 2025-12-22 19:28:38 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Now let's train for real! Let's do a longer training that will take an hour or more\n",
        "# Note: If this run is successful, you can consider doing a longer train\n",
        "# to see what happens, but that's beyond the scope of this project.\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Full training\n",
        "training_args = GRPOConfig(\n",
        "    **COMMON_GRPO_TRAINING_PARAMS,\n",
        "    # Configure the maximum number of steps to take about 30mins of time for\n",
        "    # a medium-sized experiment. (See how long the previous example took and\n",
        "    # scale up appropriately using your best guess.)\n",
        "    max_steps=100,  # ~60min\n",
        ")\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer,\n",
        "    reward_funcs=REWARD_FUNCS,\n",
        "    args=training_args,\n",
        "    train_dataset=ds,\n",
        ")\n",
        "trainer_res = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "available columns: dict_keys(['loss', 'grad_norm', 'learning_rate', 'num_tokens', 'completions/mean_length', 'completions/min_length', 'completions/max_length', 'completions/clipped_ratio', 'completions/mean_terminated_length', 'completions/min_terminated_length', 'completions/max_terminated_length', 'rewards/numbering_reward_func/mean', 'rewards/numbering_reward_func/std', 'rewards/spelling_reward_func/mean', 'rewards/spelling_reward_func/std', 'rewards/counting_reward_func/mean', 'rewards/counting_reward_func/std', 'rewards/format_reward_func/mean', 'rewards/format_reward_func/std', 'rewards/correct_answer_reward_func/mean', 'rewards/correct_answer_reward_func/std', 'reward', 'reward_std', 'frac_reward_zero_std', 'completion_length', 'kl', 'epoch', 'step'])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 122 ms (started: 2025-12-22 19:56:55 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Show the total (sum) of the rewards as well as the correct_answer_reward_func (means with in the batch)\n",
        "# Do you see the rewards increasing? Does the model get the correct answer\n",
        "# more frequently toward the end?\n",
        "# No changes needed in this cell\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# If you want to graph other columns, check these out\n",
        "print(f\"available columns: {trainer.state.log_history[0].keys()}\")\n",
        "\n",
        "log_df = pd.DataFrame(trainer.state.log_history)\n",
        "log_df[\"reward\"].plot()\n",
        "log_df[\"rewards/correct_answer_reward_func/mean\"].plot()\n",
        "\n",
        "# Show the legend\n",
        "plt.legend([\"reward\", \"rewards/correct_answer_reward_func/mean\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View the results\n",
        "Now let's try the model we just trained!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 1.06 s (started: 2025-12-22 19:57:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Save the LoRA adapters\n",
        "# No changes needed in this cell\n",
        "\n",
        "# Save the LoRA model\n",
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 952 Î¼s (started: 2025-12-22 19:57:16 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Create a function to run both the original model and the updated model\n",
        "# No changes needed in this cell\n",
        "\n",
        "\n",
        "def compare_old_and_new_model(messages):\n",
        "    from vllm import SamplingParams\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    sampling_params = SamplingParams(\n",
        "        temperature=0.8,\n",
        "        top_p=0.95,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    old = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    new = (\n",
        "        model.fast_generate(\n",
        "            text,\n",
        "            sampling_params=sampling_params,\n",
        "            lora_request=model.load_lora(\"grpo_saved_lora\"),\n",
        "        )[0]\n",
        "        .outputs[0]\n",
        "        .text\n",
        "    )\n",
        "\n",
        "    print(\"===OLD===\\n\")\n",
        "    print(old)\n",
        "\n",
        "    print(\"\\n\\n===NEW===\\n\")\n",
        "    print(new)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compare the old and new models on the letter-counting task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 993.68it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 62.54 toks/s, output: 38.72 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1004.62it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.68s/it, est. speed input: 62.53 toks/s, output: 31.56 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "<reasoning>\n",
            "Counting the number of a's in the word idea\n",
            "1. i - 0 so far\n",
            "2. d - 1 so far\n",
            "3. e - 2 so far\n",
            "4. a - 3 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "3\n",
            "</answer>\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "<reasoning>\n",
            "1. i - 1 so far\n",
            "2. d - 1 so far\n",
            "3. e - 1 so far\n",
            "4. a - 1 so far\n",
            "</reasoning>\n",
            "<answer>\n",
            "1\n",
            "</answer>\n",
            "time: 3.37 s (started: 2025-12-22 20:06:22 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's try spelling the first word from the dataset\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Load the first item from the dataset (index 0) and compare the old and new models\n",
        "compare_old_and_new_model(ds[0][\"prompt\"])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our model is better at spelling and counter letters in words! Depending on your reward functions, the size of your model, and the amount of steps trained, results may vary.\n",
        "\n",
        "For about an hour of training time, your model may not be perfect (or maybe it is), but it's definitely moving in the right direction!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Make sure the model did not forget basic facts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1431.50it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.51it/s, est. speed input: 65.72 toks/s, output: 20.22 toks/s]\n",
            "Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 1634.57it/s]\n",
            "Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.41it/s, est. speed input: 62.91 toks/s, output: 19.35 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===OLD===\n",
            "\n",
            "The capital of Japan is Tokyo.\n",
            "\n",
            "\n",
            "===NEW===\n",
            "\n",
            "The capital of Japan is Tokyo.\n",
            "time: 823 ms (started: 2025-12-22 20:07:47 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see if the model still remembers some of the facts from its original training\n",
        "# TODO: Fill out the areas where you find **********\n",
        "\n",
        "# Ask both the old and new models a question the model is likely to know,\n",
        "# e.g. a well-known capital city\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the capital of Japan?\"}\n",
        "]\n",
        "\n",
        "compare_old_and_new_model(messages)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great job! Congrats on completing the project! ðŸŽ‰ðŸ¤—"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (venv2)",
      "language": "python",
      "name": "venv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
